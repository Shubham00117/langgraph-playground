<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building a Chatbot using LangGraph</title>
    <link
        href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600;700&family=Syne:wght@400;600;800&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --bg: #0d0f14;
            --surface: #13161e;
            --surface2: #1a1e2a;
            --border: #252a38;
            --accent: #7c6af7;
            --accent2: #4fd9a4;
            --accent3: #f7a04f;
            --red: #f76f6f;
            --blue: #4fb3f7;
            --text: #e2e6f3;
            --muted: #7a8099;
            --code-bg: #0a0c12;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: var(--bg);
            color: var(--text);
            font-family: 'Syne', sans-serif;
            line-height: 1.7;
        }

        body::before {
            content: '';
            position: fixed;
            inset: 0;
            background-image: linear-gradient(rgba(124, 106, 247, 0.03)1px, transparent 1px),
                linear-gradient(90deg, rgba(124, 106, 247, 0.03)1px, transparent 1px);
            background-size: 40px 40px;
            pointer-events: none;
            z-index: 0;
        }

        .container {
            max-width: 940px;
            margin: 0 auto;
            padding: 60px 24px;
            position: relative;
            z-index: 1;
        }

        header {
            margin-bottom: 52px;
            animation: fadeDown .6s ease both;
        }

        .badge {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            background: rgba(124, 106, 247, .12);
            border: 1px solid rgba(124, 106, 247, .3);
            color: var(--accent);
            font-family: 'JetBrains Mono', monospace;
            font-size: 11px;
            letter-spacing: .1em;
            padding: 5px 14px;
            border-radius: 100px;
            text-transform: uppercase;
            margin-bottom: 20px;
        }

        h1 {
            font-size: clamp(2rem, 5vw, 3.2rem);
            font-weight: 800;
            line-height: 1.15;
            letter-spacing: -.02em;
            margin-bottom: 14px;
        }

        h1 span {
            color: var(--accent2);
        }

        .subtitle {
            color: var(--muted);
            font-size: 1rem;
            font-family: 'JetBrains Mono', monospace;
        }

        .section {
            margin-bottom: 52px;
            animation: fadeUp .5s ease both;
        }

        .section-header {
            display: flex;
            align-items: center;
            gap: 14px;
            margin-bottom: 22px;
        }

        .num {
            width: 32px;
            height: 32px;
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-family: 'JetBrains Mono', monospace;
            font-size: 13px;
            font-weight: 700;
            flex-shrink: 0;
        }

        .num.p {
            background: var(--accent);
            color: #fff;
        }

        .num.g {
            background: var(--accent2);
            color: #0d0f14;
        }

        .num.o {
            background: var(--accent3);
            color: #0d0f14;
        }

        .num.b {
            background: var(--blue);
            color: #0d0f14;
        }

        h2 {
            font-size: 1.25rem;
            font-weight: 800;
            letter-spacing: -.01em;
        }

        .card {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 20px 24px;
            margin-bottom: 14px;
            transition: border-color .2s;
        }

        .card:hover {
            border-color: rgba(124, 106, 247, .3);
        }

        .card h3 {
            font-size: .85rem;
            font-weight: 600;
            font-family: 'JetBrains Mono', monospace;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .card h3::before {
            content: '';
            width: 6px;
            height: 6px;
            border-radius: 50%;
            flex-shrink: 0;
        }

        .card h3.g {
            color: var(--accent2);
        }

        .card h3.g::before {
            background: var(--accent2);
        }

        .card h3.o {
            color: var(--accent3);
        }

        .card h3.o::before {
            background: var(--accent3);
        }

        .card h3.b {
            color: var(--blue);
        }

        .card h3.b::before {
            background: var(--blue);
        }

        .card h3.r {
            color: var(--red);
        }

        .card h3.r::before {
            background: var(--red);
        }

        .card p {
            color: #b0b8cc;
            font-size: .88rem;
            line-height: 1.65;
        }

        pre {
            background: var(--code-bg);
            border: 1px solid var(--border);
            border-left: 3px solid var(--accent);
            border-radius: 8px;
            padding: 16px 20px;
            overflow-x: auto;
            margin: 10px 0;
        }

        code {
            font-family: 'JetBrains Mono', monospace;
            font-size: .78rem;
            color: #c9d1e8;
            line-height: 1.85;
        }

        .kw {
            color: #7c6af7
        }

        .fn {
            color: #4fd9a4
        }

        .str {
            color: #f7c04f
        }

        .cm {
            color: #4a5270;
            font-style: italic
        }

        .ty {
            color: #f7a04f
        }

        .bl {
            color: #4fb3f7
        }

        .hl {
            background: rgba(124, 106, 247, .07);
            border: 1px solid rgba(124, 106, 247, .2);
            border-radius: 10px;
            padding: 14px 18px;
            margin: 10px 0;
        }

        .hl.g {
            background: rgba(79, 217, 164, .07);
            border-color: rgba(79, 217, 164, .2);
        }

        .hl.o {
            background: rgba(247, 160, 79, .07);
            border-color: rgba(247, 160, 79, .2);
        }

        .hl p {
            color: #c5cce6;
            font-size: .88rem;
        }

        .hl strong {
            color: var(--accent);
        }

        .hl.g strong {
            color: var(--accent2);
        }

        .hl.o strong {
            color: var(--accent3);
        }

        .divider {
            height: 1px;
            background: linear-gradient(90deg, transparent, var(--border), transparent);
            margin: 52px 0;
        }

        /* two-column diff */
        .diff {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 12px;
            margin: 10px 0;
        }

        @media(max-width:600px) {
            .diff {
                grid-template-columns: 1fr;
            }
        }

        .diff-box {
            background: var(--code-bg);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 14px 16px;
        }

        .diff-box .lbl {
            font-family: 'JetBrains Mono', monospace;
            font-size: .7rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: .08em;
            margin-bottom: 8px;
        }

        .diff-box.old .lbl {
            color: var(--red);
        }

        .diff-box.new .lbl {
            color: var(--accent2);
        }

        .diff-box pre {
            border: none;
            padding: 0;
            margin: 0;
            background: transparent;
        }

        /* table */
        .tw {
            overflow-x: auto;
            border-radius: 10px;
            border: 1px solid var(--border);
        }

        table {
            width: 100%;
            border-collapse: collapse;
        }

        th {
            background: var(--surface2);
            font-family: 'JetBrains Mono', monospace;
            font-size: .72rem;
            font-weight: 700;
            color: var(--accent);
            text-align: left;
            padding: 12px 18px;
            letter-spacing: .05em;
            text-transform: uppercase;
        }

        td {
            padding: 11px 18px;
            font-size: .85rem;
            border-top: 1px solid var(--border);
            vertical-align: top;
        }

        td:first-child {
            font-family: 'JetBrains Mono', monospace;
            color: var(--accent2);
            font-size: .78rem;
            white-space: nowrap;
        }

        td p {
            color: #b0b8cc;
        }

        tr:hover td {
            background: rgba(255, 255, 255, .015);
        }

        /* flowchart */
        .fc {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 14px;
            padding: 28px 16px;
            margin-bottom: 14px;
            display: flex;
            justify-content: center;
            overflow-x: auto;
        }

        .fc svg {
            overflow: visible;
        }

        @keyframes fadeDown {
            from {
                opacity: 0;
                transform: translateY(-20px)
            }

            to {
                opacity: 1;
                transform: translateY(0)
            }
        }

        @keyframes fadeUp {
            from {
                opacity: 0;
                transform: translateY(16px)
            }

            to {
                opacity: 1;
                transform: translateY(0)
            }
        }

        .section:nth-child(1) {
            animation-delay: .1s
        }

        .section:nth-child(2) {
            animation-delay: .2s
        }

        .section:nth-child(3) {
            animation-delay: .3s
        }

        .section:nth-child(4) {
            animation-delay: .4s
        }

        .section:nth-child(5) {
            animation-delay: .5s
        }

        .section:nth-child(6) {
            animation-delay: .6s
        }
    </style>
</head>

<body>
    <div class="container">

        <!-- HEADER -->
        <header>
            <div class="badge">CampusX · Module 10 · Chatbot</div>
            <h1>Building a <span>Chatbot</span><br>using LangGraph</h1>
            <p class="subtitle">// messages · add_messages · memory · thread_id · persistence</p>
        </header>

        <!-- 01 PLAN OF ACTION -->
        <div class="section">
            <div class="section-header">
                <div class="num p">58</div>
                <h2>Plan of Action — Chatbot Roadmap</h2>
            </div>
            <div class="card">
                <h3 class="g">Module Implementation Overview</h3>
                <p>This document details the core logic for building a stateful chatbot. It focuses on:
                    <strong style="color:var(--accent2)">Message State</strong> (using <code>add_messages</code> to
                    accumulate history),
                    <strong style="color:var(--accent2)">Graph Build</strong> (single-node recursive workflow),
                    <strong style="color:var(--accent3)">Persistence</strong> (integrating <code>MemorySaver</code>
                    checkpointers),
                    and <strong style="color:var(--blue)">Session Control</strong> (managing context with
                    <code>thread_id</code>).
                    The goal is to transition from stateless execution to a persistent conversational agent.
                </p>
            </div>
            <div class="hl">
                <p><strong>This video (Video 9)</strong> covers the <strong>basic chatting</strong> workflow — a single
                    node chatbot with LLM + message state, invoked in a loop.</p>
            </div>
        </div>

        <!-- 02 DESIGN -->
        <div class="section">
            <div class="section-header">
                <div class="num g">59</div>
                <h2>Design — Graph Structure</h2>
            </div>

            <div class="fc">
                <svg width="500" height="440" viewBox="0 0 500 440" font-family="'JetBrains Mono',monospace">
                    <defs>
                        <marker id="mG" markerWidth="9" markerHeight="6" refX="8" refY="3" orient="auto">
                            <polygon points="0 0,9 3,0 6" fill="#4fd9a4" />
                        </marker>
                        <marker id="mP" markerWidth="9" markerHeight="6" refX="8" refY="3" orient="auto">
                            <polygon points="0 0,9 3,0 6" fill="#7c6af7" />
                        </marker>
                    </defs>

                    <!-- __start__ -->
                    <rect x="150" y="20" width="200" height="44" rx="22" fill="#0f1218" stroke="#4fd9a4"
                        stroke-width="2.5" />
                    <text x="250" y="47" text-anchor="middle" fill="#4fd9a4" font-size="14"
                        font-weight="700">__start__</text>

                    <!-- user input label -->
                    <text x="360" y="35" fill="#7a8099" font-size="11">← user message</text>
                    <text x="360" y="50" fill="#7a8099" font-size="11">← invoked each turn</text>

                    <!-- arrow -->
                    <line x1="250" y1="64" x2="250" y2="110" stroke="#4fd9a4" stroke-width="2" marker-end="url(#mG)" />

                    <!-- chat_node -->
                    <rect x="130" y="112" width="240" height="60" rx="10" fill="#13161e" stroke="#7c6af7"
                        stroke-width="2" />
                    <text x="250" y="138" text-anchor="middle" fill="#e2e6f3" font-size="13"
                        font-weight="600">chat_node</text>
                    <text x="250" y="158" text-anchor="middle" fill="#555e7a" font-size="10">llm.invoke(messages) →
                        AIMessage</text>

                    <!-- state diagram (right side) -->
                    <rect x="360" y="112" width="130" height="60" rx="8" fill="#1a1e2a" stroke="#f7a04f"
                        stroke-width="1.5" />
                    <text x="425" y="133" text-anchor="middle" fill="#f7a04f" font-size="10"
                        font-weight="700">State</text>
                    <text x="425" y="150" text-anchor="middle" fill="#b0b8cc" font-size="9">messages:</text>
                    <text x="425" y="163" text-anchor="middle" fill="#4fd9a4" font-size="9">list[message]</text>

                    <!-- arrow -->
                    <line x1="250" y1="172" x2="250" y2="218" stroke="#7c6af7" stroke-width="2" marker-end="url(#mP)" />

                    <!-- __end__ -->
                    <rect x="150" y="220" width="200" height="44" rx="22" fill="#130d1f" stroke="#7c6af7"
                        stroke-width="2.5" />
                    <text x="250" y="247" text-anchor="middle" fill="#7c6af7" font-size="14"
                        font-weight="700">__end__</text>

                    <!-- store label -->
                    <text x="360" y="240" fill="#7a8099" font-size="11">→ store response</text>
                    <text x="360" y="255" fill="#555e7a" font-size="10"> back in state</text>

                    <!-- DIVIDER line -->
                    <line x1="20" y1="295" x2="480" y2="295" stroke="#252a38" stroke-width="1" />

                    <!-- MEMORY section below -->
                    <text x="250" y="320" text-anchor="middle" fill="#f7a04f" font-size="11" font-weight="700">WITHOUT
                        MEMORY</text>
                    <text x="250" y="340" text-anchor="middle" fill="#7a8099" font-size="10">Each invoke() starts fresh
                        — no chat history</text>

                    <text x="250" y="375" text-anchor="middle" fill="#4fd9a4" font-size="11" font-weight="700">WITH
                        MEMORY (MemorySaver)</text>
                    <text x="250" y="395" text-anchor="middle" fill="#7a8099"
                        font-size="10">config={'configurable':{'thread_id': '1'}}</text>
                    <text x="250" y="412" text-anchor="middle" fill="#7a8099" font-size="10">State persists across calls
                        for same thread_id</text>
                </svg>
            </div>
        </div>

        <div class="divider"></div>

        <!-- 03 STATE -->
        <div class="section">
            <div class="section-header">
                <div class="num o">60</div>
                <h2>State — ChatState with add_messages</h2>
            </div>

            <div class="card">
                <h3 class="g">ChatState Definition</h3>
                <pre><code><span class="kw">from</span> typing <span class="kw">import</span> TypedDict, Annotated
<span class="kw">from</span> langchain_core.messages <span class="kw">import</span> BaseMessage, HumanMessage
<span class="kw">from</span> langchain_openai <span class="kw">import</span> ChatOpenAI
<span class="kw">from</span> langgraph.graph.message <span class="kw">import</span> add_messages   <span class="cm"># special LangGraph reducer</span>

<span class="kw">class</span> <span class="ty">ChatState</span>(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]</code></pre>
            </div>

            <div class="hl g">
                <p><strong>add_messages</strong> is a LangGraph-provided reducer (from
                    <code>langgraph.graph.message</code>) that automatically <strong>appends</strong> new messages to
                    the existing list instead of overwriting. This is what gives the chatbot its <strong>conversation
                        memory</strong> within a thread. It is equivalent to
                    <code>Annotated[list[str], operator.add]</code> but built specifically for message types.
                </p>
            </div>

            <div class="diff">
                <div class="diff-box old">
                    <div class="lbl">operator.add (generic)</div>
                    <pre><code>Annotated[
  list[str],
  operator.add
]
<span class="cm"># appends any list</span></code></pre>
                </div>
                <div class="diff-box new">
                    <div class="lbl">add_messages (messages)</div>
                    <pre><code>Annotated[
  list[BaseMessage],
  add_messages
]
<span class="cm"># deduplicates + appends</span>
<span class="cm"># smart for chat history</span></code></pre>
                </div>
            </div>
        </div>

        <div class="divider"></div>

        <!-- 04 NODES + GRAPH -->
        <div class="section">
            <div class="section-header">
                <div class="num b">61</div>
                <h2>Node Function + Graph Build</h2>
            </div>

            <div class="card">
                <h3 class="g">chat_node</h3>
                <pre><code>llm = ChatOpenAI()

<span class="kw">def</span> <span class="fn">chat_node</span>(state: ChatState):
    response = llm.invoke(state[<span class="str">'messages'</span>])  <span class="cm"># LLM sees full chat history</span>
    <span class="kw">return</span> {<span class="str">'messages'</span>: [response]}           <span class="cm"># ⭐ key line — add_messages appends it</span></code></pre>
            </div>

            <div class="card">
                <h3 class="o">Graph Build</h3>
                <pre><code>graph = StateGraph(ChatState)
graph.add_node(<span class="str">'chat_node'</span>, chat_node)  <span class="cm"># single node</span>
graph.add_edge(START, <span class="str">'chat_node'</span>)
graph.add_edge(<span class="str">'chat_node'</span>, END)
chatbot = graph.compile()</code></pre>
            </div>
        </div>

        <div class="divider"></div>

        <!-- 05 RUNNING -->
        <div class="section">
            <div class="section-header">
                <div class="num p">62</div>
                <h2>Running the Chatbot</h2>
            </div>

            <div class="card">
                <h3 class="b">Single Invoke (no memory)</h3>
                <pre><code>result = chatbot.invoke({<span class="str">'messages'</span>: [HumanMessage(content=<span class="str">'What is the capital of India'</span>)]})
<span class="cm"># result['messages'] has [HumanMessage, AIMessage('New Delhi')]</span></code></pre>
            </div>

            <div class="card">
                <h3 class="g">While Loop — Interactive Chat (stateless)</h3>
                <pre><code><span class="kw">while</span> <span class="bl">True</span>:
    user_message = input(<span class="str">'Type here: '</span>)
    <span class="kw">if</span> user_message.strip().lower() <span class="kw">in</span> [<span class="str">'exit'</span>, <span class="str">'quit'</span>]: <span class="kw">break</span>
    response = chatbot.invoke({<span class="str">'messages'</span>: [HumanMessage(content=user_message)]})
    print(<span class="str">'AI:'</span>, response[<span class="str">'messages'</span>][-<span class="ty">1</span>].content)
<span class="cm"># ⚠️ Problem: each invoke starts fresh — no memory of previous turns</span></code></pre>
            </div>

            <div class="hl">
                <p><strong>Problem:</strong> Each <code>chatbot.invoke()</code> in the loop sends only the
                    <em>current</em> message. The LLM has no memory of previous turns. If you ask "What is my name?"
                    after saying your name, it won't know.
                </p>
            </div>
        </div>

        <div class="divider"></div>

        <!-- 06 MEMORY -->
        <div class="section">
            <div class="section-header">
                <div class="num g">63</div>
                <h2>Adding Memory — MemorySaver + thread_id</h2>
            </div>

            <div class="card">
                <h3 class="o">Compile with MemorySaver</h3>
                <pre><code><span class="kw">from</span> langgraph.checkpoint.memory <span class="kw">import</span> MemorySaver

memory = MemorySaver()                          <span class="cm"># in-RAM store (can use database too)</span>
chatbot = graph.compile(checkpointer=memory)    <span class="cm"># attach checkpointer</span></code></pre>
            </div>

            <div class="card">
                <h3 class="g">Loop with Memory — using config + thread_id</h3>
                <pre><code>config = {<span class="str">'configurable'</span>: {<span class="str">'thread_id'</span>: <span class="str">'1'</span>}}  <span class="cm"># ⭐ key line — links to stored state</span>

<span class="kw">while</span> <span class="bl">True</span>:
    user_message = input(<span class="str">'Type here: '</span>)
    <span class="kw">if</span> user_message.strip().lower() <span class="kw">in</span> [<span class="str">'exit'</span>, <span class="str">'quit'</span>]: <span class="kw">break</span>
    response = chatbot.invoke(
        {<span class="str">'messages'</span>: [HumanMessage(content=user_message)]},
        config=config                                     <span class="cm"># pass config</span>
    )
    print(<span class="str">'AI:'</span>, response[<span class="str">'messages'</span>][-<span class="ty">1</span>].content)
<span class="cm"># ✅ Chatbot now remembers across turns for the same thread_id</span></code></pre>
            </div>

            <div class="hl g">
                <p><strong>How it works:</strong> MemorySaver stores the full state (all messages) under the given
                    <code>thread_id</code> after each invoke. On the next invoke with the <strong>same
                        thread_id</strong>, LangGraph loads the stored state and appends the new message — giving full
                    conversation context to the LLM.
                </p>
            </div>

            <div class="hl o">
                <p><strong>Store options:</strong> <code>MemorySaver</code> uses RAM (lost on restart). For production,
                    use a <strong>database-backed store</strong> (Postgres, SQLite, Redis) so history persists across
                    sessions.</p>
            </div>
        </div>

        <div class="divider"></div>

        <!-- 07 SUMMARY TABLE -->
        <div class="section">
            <div class="section-header">
                <div class="num o">64</div>
                <h2>Key Concepts Summary</h2>
            </div>
            <div class="tw">
                <table>
                    <thead>
                        <tr>
                            <th>Concept</th>
                            <th>Explanation</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>add_messages</td>
                            <td>
                                <p>LangGraph reducer from <code>langgraph.graph.message</code>. Appends new messages to
                                    the list instead of overwriting. Smart deduplication included.</p>
                            </td>
                        </tr>
                        <tr>
                            <td>Annotated[list[BaseMessage], add_messages]</td>
                            <td>
                                <p>The state field type that enables automatic message accumulation. All incoming
                                    message lists are merged/appended.</p>
                            </td>
                        </tr>
                        <tr>
                            <td>MemorySaver</td>
                            <td>
                                <p>In-memory checkpointer. Saves full graph state per thread_id. Attach via
                                    <code>graph.compile(checkpointer=memory)</code>.
                                </p>
                            </td>
                        </tr>
                        <tr>
                            <td>thread_id</td>
                            <td>
                                <p>Unique key that identifies a conversation session. Different thread_ids = separate
                                    independent conversations.</p>
                            </td>
                        </tr>
                        <tr>
                            <td>config</td>
                            <td>
                                <p><code>{'configurable': {'thread_id': id}}</code> — passed as 2nd arg to
                                    <code>chatbot.invoke(state, config=config)</code>. Links the call to stored state.
                                </p>
                            </td>
                        </tr>
                        <tr>
                            <td>response['messages'][-1]</td>
                            <td>
                                <p>Gets the last message in the state (the AI's response to the latest user turn).</p>
                            </td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

    </div>
</body>

</html>