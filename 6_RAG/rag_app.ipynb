{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LangGraph RAG Implementation\n",
                "This notebook downloads a free PDF, indices it, and uses a LangGraph agent to answer queries by fetching relevant documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (added sentence-transformers and langchain-huggingface for free embeddings)\n",
                "!pip install -qU langgraph langchain-groq langchain-community pypdf faiss-cpu requests python-dotenv sentence-transformers langchain-huggingface"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "import requests\n",
                "from dotenv import load_dotenv\n",
                "from langchain_community.document_loaders import PyPDFLoader\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "from langchain_huggingface import HuggingFaceEmbeddings\n",
                "from langchain_groq import ChatGroq\n",
                "from langchain_community.vectorstores import FAISS\n",
                "from langchain_core.tools import tool\n",
                "from langchain_core.messages import HumanMessage\n",
                "from langgraph.graph import START, MessageGraph\n",
                "from langgraph.prebuilt import ToolNode, tools_condition\n",
                "\n",
                "# Load API keys\n",
                "load_dotenv('/Users/shubham_infinity/Desktop/Projects/LangGraph_Projects/.env')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PDF already exists.\n"
                    ]
                }
            ],
            "source": [
                "# 1. Download Free PDF from the Internet\n",
                "pdf_url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
                "pdf_path = \"attention_is_all_you_need.pdf\"\n",
                "\n",
                "if not os.path.exists(pdf_path):\n",
                "    print(\"Downloading PDF...\")\n",
                "    response = requests.get(pdf_url)\n",
                "    with open(pdf_path, \"wb\") as f:\n",
                "        f.write(response.content)\n",
                "    print(\"Download complete.\")\n",
                "else:\n",
                "    print(\"PDF already exists.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Documents indexed. Retriever is ready.\n"
                    ]
                }
            ],
            "source": [
                "# 2. Load, Chunk, and Setup Retriever\n",
                "loader = PyPDFLoader(pdf_path)\n",
                "docs = loader.load()\n",
                "\n",
                "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
                "splits = text_splitter.split_documents(docs)\n",
                "\n",
                "# Using free local HuggingFace Embeddings instead of OpenAI (which caused AuthenticationError)\n",
                "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
                "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding_model)\n",
                "retriever = vectorstore.as_retriever()\n",
                "print(\"Documents indexed. Retriever is ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Define the rag_tool to fetch relevant documents\n",
                "@tool\n",
                "def rag_tool(query):\n",
                "    \"\"\"\n",
                "    Retrieve relevant information from the pdf document.\n",
                "    Use this tool when the user asks factual / conceptual questions \n",
                "    that might be answered from the stored documents.\n",
                "    \"\"\"\n",
                "    result = retriever.invoke(query)\n",
                "    \n",
                "    context = [doc.page_content for doc in result]\n",
                "    metadata = [doc.metadata for doc in result]\n",
                "    \n",
                "    return {\n",
                "        'query': query,\n",
                "        'context': context,\n",
                "        'metadata': metadata\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "LangGraph Agent compiled successfully.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/yc/wbsm0cns4xl2dtcyv_rrvk280000gn/T/ipykernel_13497/1778625708.py:5: LangGraphDeprecatedSinceV10: MessageGraph is deprecated in LangGraph v1.0.0, to be removed in v2.0.0. Please use StateGraph with a `messages` key instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
                        "  builder = MessageGraph()\n"
                    ]
                }
            ],
            "source": [
                "# 4. Build LangGraph Agent\n",
                "# Changed from llama3-70b-8192 to llama-3.3-70b-versatile as the former was decommissioned\n",
                "llm = ChatGroq(model=\"llama-3.3-70b-versatile\").bind_tools([rag_tool])\n",
                "\n",
                "builder = MessageGraph()\n",
                "builder.add_node(\"agent\", lambda state: llm.invoke(state))\n",
                "builder.add_node(\"tools\", ToolNode([rag_tool]))\n",
                "\n",
                "builder.add_edge(START, \"agent\")\n",
                "builder.add_conditional_edges(\"agent\", tools_condition)\n",
                "builder.add_edge(\"tools\", \"agent\")\n",
                "\n",
                "rag_app = builder.compile()\n",
                "print(\"LangGraph Agent compiled successfully.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "User: What is Multi-head attention according to the document? Ensure you use the rag_tool to fetch relevant docs.\n",
                        "Agent: Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. It is a type of attention mechanism that uses multiple attention heads in parallel, each of which attends to a different subset of the input data. The outputs from each attention head are then concatenated and projected to form the final output. This allows the model to capture a wider range of contextual relationships in the input data. The Transformer uses multi-head attention in three different ways: encoder-decoder attention, self-attention in the encoder, and self-attention in the decoder.\n"
                    ]
                }
            ],
            "source": [
                "# 5. Query Function to get relative response\n",
                "def ask_agent(query: str):\n",
                "    print(f\"\\nUser: {query}\")\n",
                "    inputs = [HumanMessage(content=query)]\n",
                "    \n",
                "    # We stream the values so that we can see the final AI response\n",
                "    for event in rag_app.stream(inputs, stream_mode=\"values\"):\n",
                "        message = event[-1]\n",
                "        if message.type == \"ai\" and message.content:\n",
                "            print(f\"Agent: {message.content}\")\n",
                "\n",
                "# Example usage:\n",
                "ask_agent(\"What is Multi-head attention according to the document? Ensure you use the rag_tool to fetch relevant docs.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "myenv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
